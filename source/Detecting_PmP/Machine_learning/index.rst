Machine Learning
====================

By utilizing the high-quality PmP dataset (10,192 manual picks by `Li et al., 2002 <https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2021JB023033>`_) in southern California,
we further develop **PmPNet** (`Ding et al., 2002 <https://doi.org/10.48550/arXiv.2112.07655>`_), a deep-neural-network-based algorithm to automatically
identify PmP waves efficiently. **PmPNet** applies similar techniques in the machine learning community to address the unbalancement
of PmP datasets. The trained optimal **PmPNet** can efficiently achieve high precision and high recall simultaneously to automatically
identify PmP waves from a massive seismic database.

.. figure:: /photos/PmPNet_Trainflow.png
   :alt: Training flow of PmPNet.
   :width: 100.0%
   :align: center

   PmPNet training flow: (i) one batch of data points is fed into **PmPNet**, and the loss between the **PmPNet** output and the true
   labels is computed; and (ii) the optimizer reads in the loss and update the trainable parameters of **PmPNet**. One epoch of
   training consists of continuing this iteration until the whole dataset has been tranversed. The training phase for **PmPNet**
   is complete when the pre-selected maximum number of epochs is reached.


PmPNet Structure
----------------

**We implemented PmPNet as a convolutional residual autoencoder (RAE) with an additional prediction module.**
In our construction, the input of the **PmPNet** is a one-dimensional vector of length 297. It combines three parts:
*envelope*, *dist*, *evdp*. The length 281 *envelope* is the normalized envelope of the vertical component of seismic signals,
which has been resampled at 40 Hz and covers the time window from 2 s before to 5 s after the observed P-wave arrival.
*Dist* refers to the epicentral distance, and *evdp* refers to the focal depth, both being repeated 8 times and concatenated
to the end of the signal. The number of duplication 8 is chosen according to our experiments, and the final results presented in this
paper are not sensitive to this selection.

.. math::

  input \ x := (envelope_{1},...,envelope_{281},\underbrace{dist,...,dist}_{8 \ times},\underbrace{evdp,...,evdp}_{8 \ times})


**PmPNet** outputs three quantities: (i) the recovered input, (ii) the PmP travel time t (a positive real number), and (iii) the PmP
probability p, a real number in [0, 1] representing the probability that the input seismic signal contains a PmP phase.
**PmPNet** includes three major substructures: an encoder, a decoder, and a predictor. Similar to a standard AE, the encoder and
the decoder are trained to regenerate the input. We train the predictor to read the latent variable (generated by the encoder)
to predict the PmP probability p and travel time t. To be more precise, let *x̃* be the output of the decoder, i.e., the recovered input.
Then *z = Encoder(x)*, *x̃ = Decoder(z)*, and *(p, t) = Predictor(z)*.

.. figure:: /photos/PmPNet_Structure.jpg
   :alt: The main architecture of the PmPNet.
   :width: 100.0%
   :align: center

   The main architecture of the PmPNet and the data flow inside the network: The input of the PmPNet is a one-dimensional vector
   combining three parts: signal envelope, epicentral distance, and focal depth; PmPNet outputs three quantities: the recovered
   signal (including signal envelope, epicentral distance, and focal depth), the PmP probability p and the PmP travel time t;
   PmPNet includes three major substructures: an encoder, a decoder, and a predictor.


Loss Function of PmPNet
-----------------------

Given a training input set :math:`\{x_{i}\}^{N}_{i=1}` with *N* data points, the corresponding PmP label :math:`\{p_{true,i}\}^{N}_{i=1}`
and PmP travel time :math:`\{t_{true,i}\}_{i=1}^{N}`, we can optimize a **PmPNet** with trainable parameters set *θ*. Three
different loss functions (:math:`l_{1}`, :math:`l_{2}`, :math:`l_{3}`) are utilized for encoder-decoder, classification and travel time training respectively.
The total training loss of **PmPNet** is the sum of three individual losses:

.. math::

  Loss(θ) := \frac{1}{N}\sum_{i=1}^{N}[l_{1}(x̃_{i}(θ,x_{i}),x_{i})+l_{2}(p_{i}(θ,x_{i}),p_{true,i})+l_{3}(t_{i}(θ,x_{i}),t_{true,i})]

The variables involved are summarized as follows:

*  :math:`x_{i}` is the input datum and :math:`x̃_{i}(θ,x_{i}) := Decoder_{θ}(Encoder_{θ}(x_{i}))` is the recovered datum by the encoder-decoder pair.

*  :math:`p_{true,i}` is the true PmP label picked by experts, which is either 0 or 1. Here :math:`p_{true,i}=1` means that :math:`x_{i}` has a PmP phase, while :math:`p_{true,i}=0` means that :math:`x_{i}` does not have a PmP phase.

*  :math:`t_{true,i}` is the true PmP travel time, which is either manually picked for those labeled with PmP or theoretically computed by using the HK model (`Hadley & Kanamori, 1977 <https://strike.scec.org/scecpedia/Hadley-Kanamori>`_) for those labeled with non-PmP.

*  :math:`(p_{i},t_{i}):=Predictor_{θ}(Encoder_{θ}(x_{i}))` with :math:`p_{i}(θ,x_{i})` and :math:`t_{i}(θ,x_{i})` being the PmP probability and the PmP travel time, respectively.

Besides, each loss function is defined as:

*  :math:`l_{1}(x,x̃):=||x − x̃||_{1}` is the L1 loss between input datum and recovered datum.

*  :math:`l_{2}(p,p_{true}):=-ωp_{true}log(p(x))-(1-p_{true})log(1-p(x))` is the weighted cross-entropy loss with the weight ω chosen to be 20 balancing the importance of precision and recall.

*  :math:`l_{3}(t,t_{true}):=||t − t_{true}||_{1}` is absolute difference between the true traveltime and predicted traveltime.


Performance of PmPNet
---------------------

The validation performances of **PmPNet** shows that The proposed **PmPNet** can reach high precision(96.6%) and recall(85.3%) simultaneously.
The average travel time absolute difference is around 0.33s, while maximum difference constantly stays within 5s.

.. figure:: /photos/PmPNet_Performance1.png
   :alt: Performance of PmPNet.
   :width: 100.0%
   :align: center

   The total training loss decreases as the epoch increases.
   The precision-recall curve on validation set.
   The PmP traveltime residual between the predicted and manually picked ones on validation set.

The recovered input can capture most of the patterns from the input signal, which indicates the latent variable is indeed a good representation of the input.

.. figure:: /photos/PmPNet_Performance2.png
   :alt: Performance of PmPNet.
   :width: 100.0%
   :align: center

   The **PmPNet** recovered input and the input component on validation set.

Applying the trained **PmPNet** to the 19-year long vertical-component seismic data from January 2000 to December 2018, we are going to automatically
identify the waveforms which could contain high-quality PmP waves. To achieve the goal, we select the waveforms with the PmP label
with a probability of larger than 0.8. Result shows that the trained **PmPNet** has successfully recalled the most PmP waves (larger than 96 %) before 2011, and even for the seismic data after 2010 which are not involved in training the **PmPNet**, there is also a high recall value of larger than 85 %.

.. figure:: /photos/PmPNet_Performance3.png
   :alt: Performance of PmPNet.
   :width: 100.0%
   :align: center

   PmP picks when applying the trained **PmPNet** to real data. Blue bars show the picked PmP waves each year by the two-stage workflow,
   orange bars show the identified PmP waves each year by the **PmPNet** with the probability of greater than 0.8, and green bars show
   the overlapped PmP waves each year between the two identifiers.


Use PmPNet to Identify PmP Phase
--------------------------------

**Build the Running Environment**

.. Note::

  **PmPNet** is designed to operate on `CUDA <https://developer.nvidia.com/cuda-toolkit>`_ with at least 2,100-MiB memory.
  And Python version is better to choose 3.8.


Assuming you have `Anaconda <https://www.anaconda.com/>`_ already, set up a new environment named e.g., **PmPNet**:

.. prompt:: bash

  conda create -n PmPNet python=3.8

Install `JupyterLab <https://jupyter.org/>`_ or `Jupyter Notebook <https://jupyter.org/>`_ which is used to run **PmPNet** then:

.. prompt:: bash

  conda install -c conda-forge jupyterlab

Install `pandas <https://pandas.pydata.org/>`_ to facilitate file manipulations:

.. prompt:: bash

  pip install wheel
  pip install pandas

Install `ObsPy <https://docs.obspy.org/#>`_ which is used to process seismic data then:

.. prompt:: bash

  conda install -c conda-forge obspy

Install `scikit-learn <https://scikit-learn.org/stable/>`_ which is used to prepare the
train and validation data (e.g., standardization, randomly allocate train and validation data) then:

.. prompt:: bash

  conda install -c conda-forge scikit-learn

Install `pickle-mixin <https://pypi.org/project/pickle-mixin/>`_ which is used to transform a complex object
into a byte stream and speed up data manipulation (e.g., reading and writing) then:

.. prompt:: bash

  pip install pickle-mixin

Install `PyTorch <https://pytorch.org/>`_ which is used to construct and run **PmPNet** then:

.. Note::

  Be careful about the software compatibility between **PyTorch** and **CUDA**.
  You can check your **CUDA** version through ``nvidia-smi`` (assume you have installed the NVIDIA Linux driver),
  then choose a suitable **PyTorch** version at ``https://anaconda.org/pytorch/pytorch/files``.

.. prompt:: bash

  conda install -c pytorch pytorch=1.11.0=py3.8_cuda11.3_cudnn8.2.0_0


**Train PmPNet**

* Device configuration, Hyper-parameters setting, paths setting for data and result folders:

.. prompt:: python

  import torch
  import os
  import PmPNet as PN

  # Device configuration
  cuda = torch.cuda.is_available()
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  # Hyper-parameters
  batch_size = 200
  num_epochs = 80
  learning_rate = 1e-3

  # Paths for different folders, data and result folders
  datadir="/home/pmpboy/Github/Data"
  wdir="/home/pmpboy/Github/Result/Train_PN_result"
  if not os.path.exists(wdir):
      os.makedirs(wdir)

* read in the training data:

.. prompt:: python

  train_loader, test_loader = PN.readin_data_train(datadir,"TrainData_PmP_Net",batch_size)

* train PmPNet:

.. prompt:: python

  PN.NetTrain(wdir,"train_PN_log","net_PN_model",train_loader,learning_rate,num_epochs,batch_size,device)

We will see such output during training PmPNet:

.. prompt::

  Epoch [1/80], Step [1/420] Loss1: 3.105050,Loss2: 1.987768,Loss3: 0.338054
  Epoch [1/80], Step [101/420] Loss1: 0.527436,Loss2: 0.298014,Loss3: 0.143794
  Epoch [1/80], Step [201/420] Loss1: 0.458504,Loss2: 0.414377,Loss3: 0.150728
  Epoch [1/80], Step [301/420] Loss1: 0.396632,Loss2: 0.524836,Loss3: 0.144453
  Epoch [1/80], Step [401/420] Loss1: 0.355758,Loss2: 0.687848,Loss3: 0.141200
  Epoch [2/80], Step [1/420] Loss1: 0.371204,Loss2: 0.692910,Loss3: 0.128348
  Epoch [2/80], Step [101/420] Loss1: 0.386219,Loss2: 0.625399,Loss3: 0.130919
  Epoch [2/80], Step [201/420] Loss1: 0.307851,Loss2: 0.350751,Loss3: 0.122441
  Epoch [2/80], Step [301/420] Loss1: 0.273838,Loss2: 0.373369,Loss3: 0.145047
  Epoch [2/80], Step [401/420] Loss1: 0.279507,Loss2: 0.928377,Loss3: 0.130401
  Epoch [3/80], Step [1/420] Loss1: 0.264289,Loss2: 0.560267,Loss3: 0.149387
  Epoch [3/80], Step [101/420] Loss1: 0.269108,Loss2: 0.351606,Loss3: 0.130983
  ......

* model evaluation on test data:

.. prompt:: python

  PN.netevalu(wdir,"net_PN_model","prcurve_file","predict_PN_file",test_loader,device)

* quickly visualize the result:

.. prompt:: python

  PN.plot_modeva(wdir,"train_PN_log","prcurve_file","predict_PN_file","plot_PN_modevalu")

.. figure:: /photos/plot_PN_modevalu.png
   :alt: Quickly Visualize the Performance of Trained PmPNet.
   :width: 100.0%
   :align: center

**Apply the pre-trained PmPNet to a certain year data**

* read in the real data:

.. prompt:: python

  test_loader = PN.readin_data_real(datadir,"ValidationData_2015",batch_size)

* predict probability the waveform contains a clear PmP phase and PmP traveltime:

.. prompt:: python

  PN.netpredict(datadir,"ValidationData_2015",wdir,"net_PN_model","predict_PN_file_2015",test_loader,device)

We will see such output during the process:

.. prompt::

  NO.: 0   ID: 37272439   PmP_Prob: 0.323879  PmP_Time: 20.893116  dist: 127.9   evdp: 11.59   mag: 2.1  evtnm: 20151113_1204.CI.DTP
  NO.: 1   ID: 37198399   PmP_Prob: 0.000000  PmP_Time: 17.361309  dist: 103.3   evdp: 18.04   mag: 2.3  evtnm: 20150705_1315.CI.SYN
  NO.: 2   ID: 37150703   PmP_Prob: 0.000001  PmP_Time: 14.302899  dist: 76.6   evdp: 6.28   mag: 2.4  evtnm: 20150423_1454.CI.TOR
  NO.: 3   ID: 37501608   PmP_Prob: 0.000037  PmP_Time: 13.073999  dist: 60.6   evdp: 2.31   mag: 2.2  evtnm: 20151214_0708.CI.DPP
  NO.: 4   ID: 37508080   PmP_Prob: 0.000002  PmP_Time: 19.669258  dist: 111.8   evdp: 2.76   mag: 2.3  evtnm: 20151230_1027.CI.JVA
  NO.: 5   ID: 37148391   PmP_Prob: 0.000000  PmP_Time: 16.840071  dist: 91.2   evdp: -0.18   mag: 2.3  evtnm: 20150420_0231.CI.HEC
  NO.: 6   ID: 37305208   PmP_Prob: 0.000026  PmP_Time: 24.993418  dist: 151.4   evdp: 6.62   mag: 2.5  evtnm: 20150114_1203.CI.SYP
  NO.: 7   ID: 37301936   PmP_Prob: 0.000000  PmP_Time: 26.983143  dist: 170.9   evdp: 8.30   mag: 2.5  evtnm: 20150104_0943.CI.GATR
  NO.: 8   ID: 37402872   PmP_Prob: 0.000000  PmP_Time: 18.354214  dist: 102.4   evdp: 2.52   mag: 2.5  evtnm: 20150618_1256.CI.BLC
  NO.: 9   ID: 37403528   PmP_Prob: 0.000005  PmP_Time: 19.624937  dist: 111.2   evdp: 1.40   mag: 2.2  evtnm: 20150619_0218.CI.RVR
  ......

* quickly visualize the result:

.. prompt:: python

  PN.plot_modpredict(wdir,"predict_PN_file_2015","plot_PN_predict2015")

.. figure:: /photos/plot_PN_predict2015.png
   :alt: Quickly Visualize the Performance of Trained PmPNet.
   :width: 100.0%
   :align: center

Use PmP-traveltime-Net to Predict PmP Traveltime
----------------------------------------------------------------------------

* Device configuration, Hyper-parameters setting, paths setting for data and result folders:

.. prompt:: python

  import torch
  import os
  import PmP_traveltime_Net as PTN

  # Device configuration
  cuda = torch.cuda.is_available()
  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

  # Hyper-parameters
  batch_size = 128
  num_epochs = 200
  learning_rate = 5e-4

  # Paths for different folders, data and result folders
  datadir="/home/pmpboy/Github/Data"
  wdir="/home/pmpboy/Github/Result/Train_PTN_result"
  if not os.path.exists(wdir):
      os.makedirs(wdir)

* read in the training data:

.. prompt:: python

  train_loader, test_loader = PTN.readin_data_train(datadir,"TrainData_PmP_traveltime_Net",batch_size)

* train PmP-traveltime-Net:

.. prompt:: python

  PTN.NetTrain(wdir,"train_PTN_log","net_PTN_model",train_loader,learning_rate,num_epochs,batch_size,device)

We will see such output during training PmP-traveltime-Net:

.. prompt::

  Epoch [1/200],  Step [1/63],  Loss: 1.060057
  Epoch [1/200],  Step [51/63],  Loss: 0.161801
  Epoch [2/200],  Step [1/63],  Loss: 0.125822
  Epoch [2/200],  Step [51/63],  Loss: 0.120287
  Epoch [3/200],  Step [1/63],  Loss: 0.093617
  Epoch [3/200],  Step [51/63],  Loss: 0.084045
  Epoch [4/200],  Step [1/63],  Loss: 0.073481
  Epoch [4/200],  Step [51/63],  Loss: 0.077970
  Epoch [5/200],  Step [1/63],  Loss: 0.104802
  ......

* model evaluation on test data:

.. prompt:: python

  PTN.netevalu(wdir,"net_PTN_model","predict_PTN_file",test_loader,device)

* quickly visualize the result:

.. prompt:: python

  PTN.plot_modeva(wdir,"train_PTN_log","predict_PTN_file","plot_PTN_modevalu")

.. figure:: /photos/plot_PTN_modevalu.png
   :alt: Quickly Visualize the Performance of Trained PmPNet.
   :width: 100.0%
   :align: center

**Apply the pre-trained PmP-traveltime-Net to a certain year data**

* read in the real data:

.. prompt:: python

  test_loader = PTN.readin_data_real(datadir,"ValidationData_2015",batch_size)

* give PmP traveltime prediction on real data:

.. prompt:: python

  PTN.netpredict(datadir,"ValidationData_2015",wdir,"net_PTN_model","predict_PTN_file_2015",test_loader,device)

* quickly visualize the result:

.. prompt:: python

  PTN.plot_predict(wdir,"predict_PTN_file_2015","plot_PTN_predict_2015")

.. figure:: /photos/plot_PTN_predict_2015.png
   :alt: Quickly Visualize the Performance of Trained PmPNet.
   :width: 60.0%
   :align: center
